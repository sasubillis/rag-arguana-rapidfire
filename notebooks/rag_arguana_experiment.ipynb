{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87368,
     "status": "ok",
     "timestamp": 1766484025691,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "zPMwyu3qs9P4",
    "outputId": "6847a376-842a-4a94-9a7c-608599dd2af1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import rapidfireai\n",
    "    print(\"‚úÖ rapidfireai already installed\")\n",
    "except ImportError:\n",
    "    !pip install rapidfireai  # Takes 1 min\n",
    "    !rapidfireai init --evals # Takes 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 32909,
     "status": "ok",
     "timestamp": 1766484135040,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "vzSbP70ItG12"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "from rapidfireai import Experiment\n",
    "from rapidfireai.evals.automl import List, RFLangChainRagSpec, RFvLLMModelConfig, RFPromptManager, RFGridSearch\n",
    "import re, json\n",
    "from typing import List as listtype, Dict, Any\n",
    "\n",
    "# NB: If you get \"AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\" from Colab, just rerun this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the current working dir for next data processing instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/sasubillis/rag-arguana-rapidfire.git\n",
    "%cd rag-arguana-rapidfire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset sanity checks\n",
    "\n",
    "RAG eval pipelines assume ID consistency.\n",
    "If any of these are strings while others are integers, bad things happen silently or catastrophically:\n",
    "\n",
    "queries.jsonl -> query_id\n",
    "corpus.jsonl -> _id\n",
    "qrels.tsv -> query_id, corpus_id\n",
    "\n",
    "RapidFire expects integer IDs (because it hashes, indexes, and joins on them)\n",
    "\n",
    "#### Dataset normalization contract\n",
    "This notebook produces a canonical set of dataset files (*.final.*) that are guaranteed to use integer identifiers.\n",
    "\n",
    "If the source dataset already satisfies this constraint, files are copied unchanged. Otherwise, deterministic ID normalization is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "def prepare_final_dataset(\n",
    "    dataset_dir: Path,\n",
    "    corpus_file=\"corpus.jsonl\",\n",
    "    queries_file=\"queries.jsonl\",\n",
    "    qrels_file=\"qrels.tsv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Produces canonical files:\n",
    "      - corpus.final.jsonl\n",
    "      - queries.final.jsonl\n",
    "      - qrels.final.tsv\n",
    "\n",
    "    If IDs are already integers, originals are copied unchanged.\n",
    "    If IDs are strings, deterministic normalization is applied.\n",
    "    \"\"\"\n",
    "\n",
    "    corpus_path = dataset_dir / corpus_file\n",
    "    queries_path = dataset_dir / queries_file\n",
    "    qrels_path = dataset_dir / qrels_file\n",
    "\n",
    "    final_corpus = dataset_dir / \"corpus.final.jsonl\"\n",
    "    final_queries = dataset_dir / \"queries.final.jsonl\"\n",
    "    final_qrels  = dataset_dir / \"qrels.final.tsv\"\n",
    "\n",
    "    # --------------------\n",
    "    # Load inputs\n",
    "    # --------------------\n",
    "    with open(corpus_path) as f:\n",
    "        corpus = [json.loads(l) for l in f]\n",
    "\n",
    "    with open(queries_path) as f:\n",
    "        queries = [json.loads(l) for l in f]\n",
    "\n",
    "    qrels = pd.read_csv(\n",
    "        qrels_path,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"query_id\", \"corpus_id\", \"relevance\"]\n",
    "    )\n",
    "\n",
    "    # --------------------\n",
    "    # Detect ID types\n",
    "    # --------------------\n",
    "    corpus_id_type = type(corpus[0].get(\"_id\"))\n",
    "    query_id_type  = type(queries[0].get(\"query_id\"))\n",
    "\n",
    "    print(\"üîç ID type check\")\n",
    "    print(f\"  corpus _id: {corpus_id_type}\")\n",
    "    print(f\"  query query_id: {query_id_type}\")\n",
    "\n",
    "    # --------------------\n",
    "    # Case A: already normalized ‚Üí copy\n",
    "    # --------------------\n",
    "    if corpus_id_type is int and query_id_type is int:\n",
    "        shutil.copy(corpus_path, final_corpus)\n",
    "        shutil.copy(queries_path, final_queries)\n",
    "        shutil.copy(qrels_path, final_qrels)\n",
    "        print(\"\\n IDs already integers.\")\n",
    "        print(\"‚û° Copied originals to:\")\n",
    "        print(\"   - corpus.final.jsonl\")\n",
    "        print(\"   - queries.final.jsonl\")\n",
    "        print(\"   - qrels.final.tsv\")\n",
    "        return\n",
    "\n",
    "    # --------------------\n",
    "    # Case B: normalize ‚Üí write finals\n",
    "    # --------------------\n",
    "    print(\"\\n String IDs detected. Normalizing deterministically...\")\n",
    "\n",
    "    # Build deterministic maps\n",
    "    corpus_id_map = {doc[\"_id\"]: i for i, doc in enumerate(corpus)}\n",
    "    query_id_map  = {q[\"query_id\"]: i for i, q in enumerate(queries)}\n",
    "\n",
    "    # Rewrite corpus\n",
    "    for doc in corpus:\n",
    "        doc[\"_id\"] = corpus_id_map[doc[\"_id\"]]\n",
    "\n",
    "    # Rewrite queries\n",
    "    for q in queries:\n",
    "        q[\"query_id\"] = query_id_map[q[\"query_id\"]]\n",
    "\n",
    "    # Rewrite qrels\n",
    "    qrels[\"query_id\"]  = qrels[\"query_id\"].map(query_id_map)\n",
    "    qrels[\"corpus_id\"] = qrels[\"corpus_id\"].map(corpus_id_map)\n",
    "\n",
    "    if qrels.isnull().any().any():\n",
    "        raise ValueError(\" Qrels reference IDs not present in corpus/queries.\")\n",
    "\n",
    "    # Write canonical finals\n",
    "    with open(final_corpus, \"w\") as f:\n",
    "        for doc in corpus:\n",
    "            f.write(json.dumps(doc) + \"\\n\")\n",
    "\n",
    "    with open(final_queries, \"w\") as f:\n",
    "        for q in queries:\n",
    "            f.write(json.dumps(q) + \"\\n\")\n",
    "\n",
    "    qrels.to_csv(final_qrels, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    print(\"\\n Normalization complete.\")\n",
    "    print(\"‚û° Wrote canonical files:\")\n",
    "    print(\"   - corpus.final.jsonl\")\n",
    "    print(\"   - queries.final.jsonl\")\n",
    "    print(\"   - qrels.final.tsv\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_DIR = Path.cwd() / \"datasets\" / \"arguana\"\n",
    "prepare_final_dataset(DATASET_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "711e4c91f07d4fba9ff53c74127e6ee6",
      "17e5eb9329d24e27bf39cbfc9b3e7999",
      "76aa5984cfd545b19c7dc13e20c634d8",
      "2f09c48c8aca467bb92c38f407538665",
      "fd2c7c8e2c79452fa778cbc8b4ece4bd",
      "23514f41f307422c95d533ac8596b339",
      "fd0d05b7b9fa4fd3b02b776b6e9a716b",
      "a5f0276c839a4009916a802c42d617e5",
      "7bd81082b8c74a3ba3fd8fd2c7f2f873",
      "d54ec78f13d242fc820b26c5c0654c0c",
      "6f58467553c542b286d5b1e62fce2cd0"
     ]
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1766484412063,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "c1F9DNpKtKn5",
    "outputId": "a419b14c-caab-44f1-9966-6dc1a198c2da"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import json, random\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------\n",
    "# Project + dataset root\n",
    "# ----------------\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "dataset_dir = PROJECT_ROOT / \"datasets\" / \"arguana\"\n",
    "\n",
    "# ----------------\n",
    "# Load queries (canonical final)\n",
    "# ----------------\n",
    "arguana_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=str(dataset_dir / \"queries.final.jsonl\"),\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "# Rename only if needed\n",
    "if \"text\" in arguana_dataset.column_names:\n",
    "    arguana_dataset = arguana_dataset.rename_columns({\"text\": \"query\"})\n",
    "\n",
    "# ----------------\n",
    "# Load qrels (canonical final)\n",
    "# ----------------\n",
    "qrels = pd.read_csv(\n",
    "    dataset_dir / \"qrels.final.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"query_id\", \"corpus_id\", \"relevance\"]\n",
    ")\n",
    "\n",
    "# ----------------\n",
    "# Downsample queries + corpus jointly\n",
    "# ----------------\n",
    "sample_fraction = 0.01   # set to 1.0 for full eval\n",
    "rseed = 1\n",
    "random.seed(rseed)\n",
    "\n",
    "# Step 1: Sample queries\n",
    "sample_size = max(1, int(len(arguana_dataset) * sample_fraction))\n",
    "arguana_dataset = arguana_dataset.shuffle(seed=rseed).select(range(sample_size))\n",
    "\n",
    "# IDs are guaranteed to be integers\n",
    "query_ids = set(arguana_dataset[\"query_id\"])\n",
    "\n",
    "# Step 2: Filter qrels to sampled queries\n",
    "qrels_filtered = qrels[qrels[\"query_id\"].isin(query_ids)]\n",
    "relevant_corpus_ids = set(qrels_filtered[\"corpus_id\"].tolist())\n",
    "\n",
    "print(f\"Using {len(arguana_dataset)} queries\")\n",
    "print(f\"Found {len(relevant_corpus_ids)} relevant documents for these queries\")\n",
    "\n",
    "# ----------------\n",
    "# Step 3: Load corpus (canonical final) and filter\n",
    "# ----------------\n",
    "input_file = dataset_dir / \"corpus.final.jsonl\"\n",
    "output_file = dataset_dir / \"corpus_sampled.jsonl\"\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    all_corpus = [json.loads(line) for line in f]\n",
    "\n",
    "sampled_corpus = [\n",
    "    doc for doc in all_corpus\n",
    "    if doc[\"_id\"] in relevant_corpus_ids\n",
    "]\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for doc in sampled_corpus:\n",
    "        f.write(json.dumps(doc) + \"\\n\")\n",
    "\n",
    "print(f\"Sampled {len(sampled_corpus)} documents from {len(all_corpus)} total\")\n",
    "print(f\"Saved to: {output_file}\")\n",
    "print(f\"Filtered qrels to {len(qrels_filtered)} relevance judgments\")\n",
    "\n",
    "# Update qrels to match sampled dataset\n",
    "qrels = qrels_filtered.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 43472,
     "status": "ok",
     "timestamp": 1766484468248,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "4xxYEoqAtj28",
    "outputId": "12f3cbfa-963e-410a-d067-37ca0374961c"
   },
   "outputs": [],
   "source": [
    "experiment = Experiment(experiment_name=\"exp1-arguana-rag-colab\", mode=\"evals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1785,
     "status": "ok",
     "timestamp": 1766484707177,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "n529qQVgtpta"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "# Per-Actor batch size for hardware efficiency\n",
    "batch_size = 50\n",
    "\n",
    "# 2 chunk sizes x 2 reranking top-n = 4 combinations in total\n",
    "rag_gpu = RFLangChainRagSpec(\n",
    "    document_loader=DirectoryLoader(\n",
    "        path=str(dataset_dir / \"arguana\"),\n",
    "        glob=\"corpus_sampled.jsonl\",\n",
    "        loader_cls=JSONLoader,\n",
    "        loader_kwargs={\n",
    "            \"jq_schema\": \".\",\n",
    "            \"content_key\": \"text\",\n",
    "            \"metadata_func\": lambda record, metadata: {\n",
    "                \"corpus_id\": int(record.get(\"_id\"))\n",
    "            },  # store the document id\n",
    "            \"json_lines\": True,\n",
    "            \"text_content\": False,\n",
    "        },\n",
    "        sample_seed=42,\n",
    "    ),\n",
    "    # 2 chunking strategies with different chunk sizes\n",
    "    text_splitter=List([\n",
    "            RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "                encoding_name=\"gpt2\", chunk_size=256, chunk_overlap=32\n",
    "            ),\n",
    "            RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "                encoding_name=\"gpt2\", chunk_size=128, chunk_overlap=32\n",
    "            ),\n",
    "            RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "                encoding_name=\"gpt2\", chunk_size=64, chunk_overlap=32\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    embedding_cls=HuggingFaceEmbeddings,\n",
    "    embedding_kwargs={\n",
    "        \"model_name\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        \"model_kwargs\": {\"device\": \"cuda:0\"},\n",
    "        \"encode_kwargs\": {\"normalize_embeddings\": True, \"batch_size\": batch_size},\n",
    "    },\n",
    "    vector_store=None,  # uses FAISS by default\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 8},\n",
    "    # 2 reranking strategies with different top-n values\n",
    "    reranker_cls=CrossEncoderReranker,\n",
    "    reranker_kwargs={\n",
    "        \"model_name\": \"cross-encoder/ms-marco-MiniLM-L6-v2\",\n",
    "        \"model_kwargs\": {\"device\": \"cpu\"},\n",
    "        \"top_n\": List([2]),\n",
    "        #\"top_n\": List([2, 5]),\n",
    "    },\n",
    "    enable_gpu_search=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1766484711567,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "kfYsHjKfuuJJ"
   },
   "outputs": [],
   "source": [
    "def sample_preprocess_fn(\n",
    "    batch: Dict[str, listtype], rag: RFLangChainRagSpec, prompt_manager: RFPromptManager\n",
    ") -> Dict[str, listtype]:\n",
    "    \"\"\"Function to prepare the final inputs given to the generator model\"\"\"\n",
    "\n",
    "    INSTRUCTIONS = \"Utilize your financial knowledge, give your answer or opinion to the input question or subject matter.\"\n",
    "\n",
    "    # Perform batched retrieval over all queries; returns a list of lists of k documents per query\n",
    "    all_context = rag.get_context(batch_queries=batch[\"query\"], serialize=False)\n",
    "\n",
    "    # Extract the retrieved document ids from the context\n",
    "    retrieved_documents = [\n",
    "        [doc.metadata[\"corpus_id\"] for doc in docs] for docs in all_context\n",
    "    ]\n",
    "\n",
    "    # Serialize the retrieved documents into a single string per query using the default template\n",
    "    serialized_context = rag.serialize_documents(all_context)\n",
    "    batch[\"query_id\"] = [int(query_id) for query_id in batch[\"query_id\"]]\n",
    "\n",
    "    # Each batch to contain conversational prompt, retrieved documents, and original 'query_id', 'query', 'metadata'\n",
    "    return {\n",
    "        \"prompts\": [\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": INSTRUCTIONS},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Here is some relevant context:\\n{context}. \\nNow answer the following question using the context provided earlier:\\n{question}\",\n",
    "                },\n",
    "            ]\n",
    "            for question, context in zip(batch[\"query\"], serialized_context)\n",
    "        ],\n",
    "        \"retrieved_documents\": retrieved_documents,\n",
    "        **batch,\n",
    "    }\n",
    "\n",
    "\n",
    "def sample_postprocess_fn(batch: Dict[str, listtype]) -> Dict[str, listtype]:\n",
    "    \"\"\"Function to postprocess outputs produced by generator model\"\"\"\n",
    "    # Get ground truth documents for each query; can be done in preprocess_fn too but done here for clarity\n",
    "    batch[\"ground_truth_documents\"] = [\n",
    "        qrels[qrels[\"query_id\"] == query_id][\"corpus_id\"].tolist()\n",
    "        for query_id in batch[\"query_id\"]\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1766484714522,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "YotlVN-6u5Je"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def compute_ndcg_at_k(retrieved_docs: set, expected_docs: set, k=5):\n",
    "    \"\"\"Utility function to compute NDCG@k\"\"\"\n",
    "    relevance = [1 if doc in expected_docs else 0 for doc in list(retrieved_docs)[:k]]\n",
    "    dcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(relevance))\n",
    "\n",
    "    # IDCG: perfect ranking limited by min(k, len(expected_docs))\n",
    "    ideal_length = min(k, len(expected_docs))\n",
    "    ideal_relevance = [3] * ideal_length + [0] * (k - ideal_length)\n",
    "    idcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(ideal_relevance))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "\n",
    "def compute_rr(retrieved_docs: set, expected_docs: set):\n",
    "    \"\"\"Utility function to compute Reciprocal Rank (RR) for a single query\"\"\"\n",
    "    rr = 0\n",
    "    for i, retrieved_doc in enumerate(retrieved_docs):\n",
    "        if retrieved_doc in expected_docs:\n",
    "            rr = 1 / (i + 1)\n",
    "            break\n",
    "    return rr\n",
    "\n",
    "\n",
    "def sample_compute_metrics_fn(batch: Dict[str, listtype]) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Function to compute all eval metrics based on retrievals and/or generations\"\"\"\n",
    "\n",
    "    true_positives, precisions, recalls, f1_scores, ndcgs, rrs = 0, [], [], [], [], []\n",
    "    total_queries = len(batch[\"query\"])\n",
    "\n",
    "    for pred, gt in zip(batch[\"retrieved_documents\"], batch[\"ground_truth_documents\"]):\n",
    "        expected_set = set(gt)\n",
    "        retrieved_set = set(pred)\n",
    "\n",
    "        true_positives = len(expected_set.intersection(retrieved_set))\n",
    "        precision = true_positives / len(retrieved_set) if len(retrieved_set) > 0 else 0\n",
    "        recall = true_positives / len(expected_set) if len(expected_set) > 0 else 0\n",
    "        f1 = (\n",
    "            2 * precision * recall / (precision + recall)\n",
    "            if (precision + recall) > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        ndcgs.append(compute_ndcg_at_k(retrieved_set, expected_set, k=5))\n",
    "        rrs.append(compute_rr(retrieved_set, expected_set))\n",
    "\n",
    "    return {\n",
    "        \"Total\": {\"value\": total_queries},\n",
    "        \"Precision\": {\"value\": sum(precisions) / total_queries},\n",
    "        \"Recall\": {\"value\": sum(recalls) / total_queries},\n",
    "        \"F1 Score\": {\"value\": sum(f1_scores) / total_queries},\n",
    "        \"NDCG@5\": {\"value\": sum(ndcgs) / total_queries},\n",
    "        \"MRR\": {\"value\": sum(rrs) / total_queries},\n",
    "    }\n",
    "\n",
    "\n",
    "def sample_accumulate_metrics_fn(\n",
    "    aggregated_metrics: Dict[str, listtype],\n",
    ") -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Function to accumulate eval metrics across all batches\"\"\"\n",
    "\n",
    "    num_queries_per_batch = [m[\"value\"] for m in aggregated_metrics[\"Total\"]]\n",
    "    total_queries = sum(num_queries_per_batch)\n",
    "    algebraic_metrics = [\"Precision\", \"Recall\", \"F1 Score\", \"NDCG@5\", \"MRR\"]\n",
    "\n",
    "    return {\n",
    "        \"Total\": {\"value\": total_queries},\n",
    "        **{\n",
    "            metric: {\n",
    "                \"value\": sum(\n",
    "                    m[\"value\"] * queries\n",
    "                    for m, queries in zip(\n",
    "                        aggregated_metrics[metric], num_queries_per_batch\n",
    "                    )\n",
    "                )\n",
    "                / total_queries,\n",
    "                \"is_algebraic\": True,\n",
    "                \"value_range\": (0, 1),\n",
    "            }\n",
    "            for metric in algebraic_metrics\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1766484718360,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "joW5Pgr0u6sX"
   },
   "outputs": [],
   "source": [
    "vllm_config1 = RFvLLMModelConfig(\n",
    "    model_config={\n",
    "        \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "        \"dtype\": \"half\",\n",
    "        \"gpu_memory_utilization\": 0.25,\n",
    "        \"tensor_parallel_size\": 1,\n",
    "        \"distributed_executor_backend\": \"mp\",\n",
    "        \"enable_chunked_prefill\": False,\n",
    "        \"enable_prefix_caching\": False,\n",
    "        \"max_model_len\": 3000,\n",
    "        \"disable_log_stats\": True,  # Disable vLLM progress logging\n",
    "        \"enforce_eager\": True,\n",
    "        \"disable_custom_all_reduce\": True,\n",
    "    },\n",
    "    sampling_params={\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 128,\n",
    "    },\n",
    "    rag=rag_gpu,\n",
    "    prompt_manager=None,\n",
    ")\n",
    "\n",
    "batch_size = 3 # Smaller batch size for generation\n",
    "config_set = {\n",
    "    \"vllm_config\": vllm_config1,  # Only 1 generator, but it represents 4 full configs\n",
    "    \"batch_size\": batch_size,\n",
    "    \"preprocess_fn\": sample_preprocess_fn,\n",
    "    \"postprocess_fn\": sample_postprocess_fn,\n",
    "    \"compute_metrics_fn\": sample_compute_metrics_fn,\n",
    "    \"accumulate_metrics_fn\": sample_accumulate_metrics_fn,\n",
    "    \"online_strategy_kwargs\": {\n",
    "        \"strategy_name\": \"normal\",\n",
    "        \"confidence_level\": 0.95,\n",
    "        \"use_fpc\": True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1766485838789,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "2-bJ2gYnvABU"
   },
   "outputs": [],
   "source": [
    "# Simple grid search across all config combinations: 4 total (2 chunkers √ó 2 rerankers)\n",
    "config_group = RFGridSearch(config_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1766484756535,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "abPRdsKqvDN9",
    "outputId": "b447740e-a810-4328-95d9-d3ee8f814067"
   },
   "outputs": [],
   "source": [
    "# Display the Ray dashboard in the Colab notebook\n",
    "from google.colab import output\n",
    "output.serve_kernel_port_as_iframe(8855)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8851/dispatcher/get-pipeline-config-json/15": {
       "data": "eyJjb250ZXh0X2lkIjoyLCJwaXBlbGluZV9jb25maWdfanNvbiI6eyJiYXRjaF9zaXplIjozLCJtb2RlbF9jb25maWciOnsiZGlzYWJsZV9jdXN0b21fYWxsX3JlZHVjZSI6dHJ1ZSwiZGlzYWJsZV9sb2dfc3RhdHMiOnRydWUsImRpc3RyaWJ1dGVkX2V4ZWN1dG9yX2JhY2tlbmQiOiJtcCIsImR0eXBlIjoiaGFsZiIsImVuYWJsZV9jaHVua2VkX3ByZWZpbGwiOmZhbHNlLCJlbmFibGVfcHJlZml4X2NhY2hpbmciOmZhbHNlLCJlbmZvcmNlX2VhZ2VyIjp0cnVlLCJncHVfbWVtb3J5X3V0aWxpemF0aW9uIjowLjI1LCJtYXhfbW9kZWxfbGVuIjozMDAwLCJtb2RlbCI6IlF3ZW4vUXdlbjIuNS0wLjVCLUluc3RydWN0IiwidGVuc29yX3BhcmFsbGVsX3NpemUiOjF9LCJvbmxpbmVfc3RyYXRlZ3lfa3dhcmdzIjp7ImNvbmZpZGVuY2VfbGV2ZWwiOjAuOTUsInN0cmF0ZWd5X25hbWUiOiJub3JtYWwiLCJ1c2VfZnBjIjp0cnVlfSwicGlwZWxpbmVfdHlwZSI6InZsbG0iLCJyYWdfY29uZmlnIjp7ImNodW5rX292ZXJsYXAiOjMyLCJjaHVua19zaXplIjo2NCwiayI6OCwic2VhcmNoX3R5cGUiOiJzaW1pbGFyaXR5IiwidG9wX24iOjJ9LCJzYW1wbGluZ19wYXJhbXMiOnsibWF4X3Rva2VucyI6MTI4LCJ0ZW1wZXJhdHVyZSI6MC44LCJ0b3BfcCI6MC45NX19fQo=",
       "headers": [
        [
         "content-length",
         "653"
        ],
        [
         "content-type",
         "application/json"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      },
      "http://localhost:8851/dispatcher/list-all-pipeline-ids": {
       "data": "W10K",
       "headers": [
        [
         "content-length",
         "3"
        ],
        [
         "content-type",
         "application/json"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 163521,
     "status": "ok",
     "timestamp": 1766487664869,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "sPwGpCGSvGLp",
    "outputId": "af434f25-025f-4d17-f233-d2882f0e665c"
   },
   "outputs": [],
   "source": [
    "# Launch evals of all RAG configs in the config_group with swap granularity of 4 chunks\n",
    "# NB: If your machine has more than 1 GPU, set num_actors to that number\n",
    "results = experiment.run_evals(\n",
    "    config_group=config_group,\n",
    "    dataset=arguana_dataset,\n",
    "    num_actors=1,\n",
    "    num_shards=4,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1766487796988,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "mBxi0R-nvKRP",
    "outputId": "be099e81-94cf-45fb-fd3c-e353f800c416"
   },
   "outputs": [],
   "source": [
    "# Convert results dict to DataFrame\n",
    "results_df = pd.DataFrame([\n",
    "    {k: v['value'] if isinstance(v, dict) and 'value' in v else v for k, v in {**metrics_dict, 'run_id': run_id}.items()}\n",
    "    for run_id, (_, metrics_dict) in results.items()\n",
    "])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "executionInfo": {
     "elapsed": 11857,
     "status": "ok",
     "timestamp": 1766487833238,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "ZLZGBBM8vNjl",
    "outputId": "2d0e7d40-0abe-4780-af53-89c4b0c6e671"
   },
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('''\n",
    "<button id=\"continue-btn\" style=\"padding: 10px 20px; font-size: 16px;\">Click to End Experiment</button>\n",
    "'''))\n",
    "\n",
    "# eval_js blocks until the Promise resolves\n",
    "output.eval_js('''\n",
    "new Promise((resolve) => {\n",
    "    document.getElementById(\"continue-btn\").onclick = () => {\n",
    "        document.getElementById(\"continue-btn\").disabled = true;\n",
    "        document.getElementById(\"continue-btn\").innerText = \"Continuing...\";\n",
    "        resolve(\"clicked\");\n",
    "    };\n",
    "})\n",
    "''')\n",
    "\n",
    "# Actually end the experiment after the button is clicked\n",
    "experiment.end()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1766487840311,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "bFWA50drvRy0",
    "outputId": "0bb8d76d-cdbf-40b5-8ba0-720916169e10"
   },
   "outputs": [],
   "source": [
    "# Get the experiment-specific log file\n",
    "log_file = experiment.get_log_file_path()\n",
    "\n",
    "print(f\"üìÑ Log File: {log_file}\")\n",
    "print()\n",
    "\n",
    "if log_file.exists():\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Last 30 lines of {log_file.name}:\")\n",
    "    print(\"=\" * 80)\n",
    "    with open(log_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[-30:]:\n",
    "            print(line.rstrip())\n",
    "else:\n",
    "    print(f\"‚ùå Log file not found: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 858
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1766489029534,
     "user": {
      "displayName": "Sreenu Sasubilli",
      "userId": "10475316820965342955"
     },
     "user_tz": 480
    },
    "id": "pIbnL01l7YbW",
    "outputId": "5d9daae0-ce3d-47ae-f766-319c7fc14d84"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only the relevant columns\n",
    "plot_df = results_df[[\n",
    "    \"chunk_size\",\n",
    "    \"Precision\",\n",
    "    \"Recall\",\n",
    "    \"F1 Score\",\n",
    "    \"NDCG@5\",\n",
    "    \"MRR\",\n",
    "    \"Processing Time\"\n",
    "]].copy()\n",
    "\n",
    "# Sort by chunk size for clean plots\n",
    "plot_df = plot_df.sort_values(\"chunk_size\")\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "metrics = [\n",
    "    (\"Precision\", \"Precision vs Chunk Size\"),\n",
    "    (\"Recall\", \"Recall vs Chunk Size\"),\n",
    "    (\"F1 Score\", \"F1 Score vs Chunk Size\"),\n",
    "    (\"NDCG@5\", \"NDCG@5 vs Chunk Size\"),\n",
    "    (\"MRR\", \"MRR vs Chunk Size\"),\n",
    "    (\"Processing Time\", \"Processing Time vs Chunk Size (seconds)\")\n",
    "]\n",
    "\n",
    "for ax, (metric, title) in zip(axes, metrics):\n",
    "    ax.plot(plot_df[\"chunk_size\"], plot_df[metric], marker=\"o\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Chunk Size\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xticks(plot_df[\"chunk_size\"])   # üëà THIS LINE\n",
    "    ax.grid(True)\n",
    "    ax.axvline(x=64, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNs5V7Q3EuJ4hyvetn78JUd",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17e5eb9329d24e27bf39cbfc9b3e7999": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23514f41f307422c95d533ac8596b339",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fd0d05b7b9fa4fd3b02b776b6e9a716b",
      "value": "Generating‚Äátrain‚Äásplit:‚Äá"
     }
    },
    "23514f41f307422c95d533ac8596b339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f09c48c8aca467bb92c38f407538665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d54ec78f13d242fc820b26c5c0654c0c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6f58467553c542b286d5b1e62fce2cd0",
      "value": "‚Äá1406/0‚Äá[00:00&lt;00:00,‚Äá27763.51‚Äáexamples/s]"
     }
    },
    "6f58467553c542b286d5b1e62fce2cd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "711e4c91f07d4fba9ff53c74127e6ee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17e5eb9329d24e27bf39cbfc9b3e7999",
       "IPY_MODEL_76aa5984cfd545b19c7dc13e20c634d8",
       "IPY_MODEL_2f09c48c8aca467bb92c38f407538665"
      ],
      "layout": "IPY_MODEL_fd2c7c8e2c79452fa778cbc8b4ece4bd"
     }
    },
    "76aa5984cfd545b19c7dc13e20c634d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5f0276c839a4009916a802c42d617e5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7bd81082b8c74a3ba3fd8fd2c7f2f873",
      "value": 1
     }
    },
    "7bd81082b8c74a3ba3fd8fd2c7f2f873": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5f0276c839a4009916a802c42d617e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d54ec78f13d242fc820b26c5c0654c0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd0d05b7b9fa4fd3b02b776b6e9a716b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd2c7c8e2c79452fa778cbc8b4ece4bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
